import requests
from bs4 import BeautifulSoup
from pymongo import MongoClient, errors
from datetime import datetime
import schedule
import time

MONGO_URI = "mongodb+srv://myuser:mypassword123!@cluster0.sqzxe33.mongodb.net/?appName=Cluster0"
client = MongoClient(MONGO_URI)
db = client["newsdb"]
collection = db["news"]

collection.create_index("link", unique=True)

def fetch_headlines(page):
    url = f"https://news.naver.com/section/105?page={page}"
    response = requests.get(url, headers={
        "User-Agent": "Mozilla/5.0"
    })
    response.raise_for_status()

    soup = BeautifulSoup(response.text, "html.parser")

    items = soup.select("li.sa_item")

    results = []

    for item in items:
        title_tag = item.select_one("a.sa_text_title")
        press_tag = item.select_one("div.sa_text_press")
        lede_tag = item.select_one("div.sa_text_lede")

        if not title_tag:
            continue

        title = title_tag.get_text(strip=True)
        link = "https://news.naver.com" + title_tag.get("href")
        press = press_tag.get_text(strip=True) if press_tag else ""
        lede = lede_tag.get_text(strip=True) if lede_tag else ""

        results.append({
            "title": title,
            "link": link,
            "press": press,
            "lede": lede,
            "created_at": datetime.utcnow()
        })

    return results


def run_crawler():
    print("\n===== í¬ë¡¤ë§ ì‹œì‘ =====")

    for p in range(1, 11):
        print(f"í¬ë¡¤ë§ {p} í˜ì´ì§€")
        headlines = fetch_headlines(p)

        for item in headlines:
            try:
                collection.insert_one(item)
                print("ì €ì¥ë¨:", item["title"])
            except errors.DuplicateKeyError:
                print("ì¤‘ë³µ ìŠ¤í‚µ:", item["title"])

    print("===== í¬ë¡¤ë§ ì¢…ë£Œ =====\n")


# ğŸ”¥ 10ì´ˆë§ˆë‹¤ ì‹¤í–‰
schedule.every(60).seconds.do(run_crawler)

if __name__ == "__main__":
    print("ìë™ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì¤‘... (1ë¶„ë§ˆë‹¤ ì‹¤í–‰)")
    run_crawler()  # ìµœì´ˆ 1ë²ˆ ì‹¤í–‰

    while True:
        schedule.run_pending()
        time.sleep(1)
